{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task\n\n-  extract Point of Interest (POI) Names and Street Names from unformatted Indonesia addresses.\n\n# Submisison\n\n- POI/street\n- can be empty for POI or street. Both can also be empty which = \"/\"\n- auto complete missing words\n\n# Evaluation\n\n- average of accuracy score of each address\n\n# [AddressNet](https://github.com/jasonrig/address-net)\n\n- Encode each character that includes punctuation with 8 bit vector\n- Feed through Bi-directional GRU then pass through dense layer and softmax to predict 2 class which is POI and street name\n- rely on data augmentation\n- add noise randomly with typo\n\n# [DL Specific Info Extraction](https://towardsdatascience.com/deep-learning-for-specific-information-extraction-from-unstructured-texts-12c5b9dceada)\n\n- Create language model (ULMFit, ELmo) RNN embedding\n- Text vectorization with word2vec, GLoVe, tf-idf\n- Associate vector of POI and street name with address vector\n- Takes in 3 variable length vector each passed through LSTM: phrase, context, phrase + context\n- https://www.linkedin.com/pulse/text-data-processing-deep-learning-word-embeddingrnn-lstm-rahul-jain/\n\n\n# Using DistilBERT with sentence-transformer\n\n# [Deep Learning for Named Entity Recognition - Kfir Bar](https://www.youtube.com/watch?v=TUXbXwu17KE)\n\n- Use IOB annotation. Beginning of named entity, end of named entity and other\n- Create embedding of each word. Can take a window as context. Output will be IOB of interested entity i.e. B-POI, E-POI, B-StreetName, E-StreetName, Other. Softmax final\n- RNN might be better where we capture output of previous word + embedding of current word\n- Bi-directional LSTM better able to capture right and left\n- Can be multiple layer LSTM\n- Use CRF as final layer\n- Add character based encoding as part of input vector\n\n# [State-of-the-art named entity recognition with BERT](https://www.youtube.com/watch?v=aUGCHVbs6oo)\n\n- Char-CNN-BiLSTM-CRF\n- Flatten 4 features Tokens + Casing presence + POS + Char CNN\n\n# [Intro to Deep Learning NLP with PyTorch 05 Bi LSTMs and Named Entity Recognition](https://github.com/PythonWorkshop/intro-to-nlp-with-pytorch/tree/master/Named_Entity_Recognition)\n\n\n# [NLP Tutorial 16 - CV and Resume Parsing with Custom NER Training with SpaCy](https://kgptalkie.com/resume-and-cv-summarization/)\n\n- purely using spacy\n\n# [Building BERT extraction model](https://www.youtube.com/watch?v=MqQ7rqRllIc)\n\n- https://github.com/abhishekkrthakur/bert-entity-extraction\n\n# [Sequence tagging with tensorflow](https://github.com/guillaumegenthial/sequence_tagging)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scipy sklearn torchvision tqdm jdc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport matplotlib.pyplot as plt\n%matplotlib notebook\nplt.rcParams[\"figure.figsize\"] = [20, 10]\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\ntorch.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports for this tutorial\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim\nimport jdc\nimport json\nfrom collections import defaultdict, OrderedDict\nimport math\nimport numpy as np\n\ntorch.manual_seed(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rootPath = \"/kaggle/input/scl2021address-extraction\"\n# Raw Files\ntrainDs = pd.read_csv(f\"{rootPath}/train.csv\")\ntestDs = pd.read_csv(f\"{rootPath}/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Training Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getLabel(words, poi, street):\n    labels = []\n    for idx, word in enumerate(words):\n        if word in poi and (False if idx == 0 else (labels[idx - 1] == 'B-POI' or labels[idx -1] == 'I-POI')):\n            labels.append(\"I-POI\")\n        elif word in poi:\n            labels.append(\"B-POI\")\n        elif word in street and (False if idx == 0 else (labels[idx - 1] == 'B-Street' or labels[idx - 1] == 'I-Street')):\n            labels.append(\"I-Street\")\n        elif word in street:\n            labels.append(\"B-Street\")\n        if word not in poi and word not in street:\n            labels.append(\"O\")\n    return labels\n\n\ndef prepare_sequence(seq, to_ix):\n    \"\"\"\n    Convert words or tags to intigers and return a Pytorch tensor.\n    :param seq: Sequence of words.\n    :type seq: list\n    :param to_ix: Dictionary mapping words or tags to intigers.\n    :return: A Pytorch tensor of indices.\n    :rtype: Tensor\n    \"\"\"\n    idxs = [to_ix[w] for w in seq]\n    return torch.tensor(idxs, dtype=torch.long)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop = stopwords.words('indonesian')\n\n# Preprocess\n# Remove stop words\n\ntrainMini = trainDs\ntrainMini[\"poi\"] = trainMini[\"POI/street\"].str.split(\"/\").str[0].str.split(\" \")\ntrainMini[\"street\"] = trainMini[\"POI/street\"].str.split(\"/\").str[1].str.split(\" \")\ntrainMini['words'] = trainMini[\"raw_address\"].str.split(r\"\\W+\").apply(lambda x: [word for word in x if word not in (stop)])\ntrainMini['labels'] = trainMini.apply(lambda x: getLabel(x['words'], x['poi'], x['street']), axis=1)\ndata = [item for sublist in trainMini[['words', 'labels']].apply(lambda x: list(zip(*x)), axis=1).values for item in sublist]\nvocab = set([item for sublist in trainMini['words'].values for item in sublist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training data split\nnum_train = math.floor(len(data) * 0.8) # 80% to train\ntraining_data, test_data = data[:num_train], data[num_train:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/working/data.pkl', 'wb') as f:\n    pickle.dump(data, f)\n\nwith open('/kaggle/working/vocab.pkl', 'wb') as f:\n    pickle.dump(vocab, f)\n    \nwith open('/kaggle/working/train.pkl', 'wb') as f:\n    pickle.dump(training_data, f)\n    \nwith open('/kaggle/working/test.pkl', 'wb') as f:\n    pickle.dump(training_data, f)\n    \ntrainMini.to_csv(\"/kaggle/working/df.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Torch Create"},{"metadata":{"trusted":true},"cell_type":"code","source":"START_TAG = \"<START>\"\nSTOP_TAG = \"<STOP>\"\nEMBEDDING_DIM = 5\nHIDDEN_DIM = 4\nMINIBATCH_SIZE = 2\nLEARNING_WEIGHT = 5e-2\nWEIGHT_DECAY = 1e-4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BiLSTM_CRF(nn.Module):\n\n    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n        \"\"\"Initialize network.\"\"\"\n        super(BiLSTM_CRF, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.tag_to_ix = tag_to_ix\n        self.tagset_size = len(tag_to_ix)\n\n        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n                            num_layers=1, bidirectional=True)\n\n        # Maps the output of the LSTM into tag space.\n        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n\n        # Matrix of transition parameters.  Entry i,j is the score of\n        # transitioning *to* i *from* j.\n        self.transitions = nn.Parameter(\n            torch.randn(self.tagset_size, self.tagset_size))\n\n        # These two statements enforce the constraint that we never transfer\n        # to the start tag and we never transfer from the stop tag\n        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n\n        self.hidden = self.init_hidden()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\ndef init_hidden(self):\n    \"\"\"Two tensors to hold hidden states, one for each\n    LSTM direction with dimensions of (num_layers, \n    minibatch, hidden_dim)\"\"\"\n    # Minibatch small because small dataset below\n    return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n            torch.randn(2, 1, self.hidden_dim // 2).to(device))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\n\ndef _forward_alg(self, feats):\n    \"\"\"Core magic of the Conditional Random Field.  \n    \n    Input:\n        The word embeddeding vectors for a sentence\n    \n    Since weâ€™re using PyTorch to compute gradients for us, \n    we technically only need the forward part of the forward-backward \n    algorithm \"\"\"\n    # Do the forward algorithm to compute the partition function\n    init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n    # START_TAG (\"<START>\") has all of the score.\n    init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n\n    forward_var = init_alphas\n\n    # Iterate through the sentence\n    for feat in feats:\n        alphas_t = []  # The forward tensors at this timestep\n        for next_tag in range(self.tagset_size):\n            # broadcast the emission score: it is the same regardless of\n            # the previous tag\n            emit_score = feat[next_tag].view(\n                1, -1).expand(1, self.tagset_size)\n            # the ith entry of trans_score is the score of transitioning to\n            # next_tag from i\n            trans_score = self.transitions[next_tag].view(1, -1)\n            # The ith entry of next_tag_var is the value for the\n            # edge (i -> next_tag) before we do log-sum-exp\n            next_tag_var = forward_var + trans_score + emit_score\n            # The forward variable for this tag is log-sum-exp of all the\n            # scores.\n            alphas_t.append(log_sum_exp(next_tag_var).view(1))\n        forward_var = torch.cat(alphas_t).view(1, -1)\n    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n    alpha = log_sum_exp(terminal_var)\n    return alpha\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\ndef _get_lstm_features(self, sentence):\n    \"\"\"Compute output vector of BiLSTM - used in \n    the forward pass of network\"\"\"\n    self.hidden = self.init_hidden()\n    embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n    lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n    # Map LSTM features into tag space\n    lstm_feats = self.hidden2tag(lstm_out)\n    return lstm_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\ndef _score_sentence(self, feats, tags):\n    \"\"\"Gives the score of a provided tag sequence\"\"\"\n    # Gives the score of a provided tag sequence\n    score = torch.zeros(1).to(device)\n    tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), \n                      tags])\n    for i, feat in enumerate(feats):\n        score = score + \\\n            self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n    score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\ndef _viterbi_decode(self, feats):\n    \"\"\"Implements Viterbi algorithm for finding most likely sequence of labels.\n    Used in the forward pass of the network.\n\n    We take the maximum over the previous states as opposed to the sum. \n    Input:\n        loglikelihoods: torch tensor.\n    Output:\n        tuple. The first entry is the loglikelihood of this sequence. The second is \n        the most likely sequence of labels. \n    \"\"\"\n    backpointers = []\n\n    # Initialize the viterbi variables in log space\n    init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n    init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n\n    # forward_var at step i holds the viterbi variables for step i-1\n    forward_var = init_vvars\n    for feat in feats:\n        bptrs_t = []  # holds the backpointers for this step\n        viterbivars_t = []  # holds the viterbi variables for this step\n\n        for next_tag in range(self.tagset_size):\n            # next_tag_var[i] holds the viterbi variable for tag i at the\n            # previous step, plus the score of transitioning\n            # from tag i to next_tag.\n            # We don't include the emission scores here because the max\n            # does not depend on them (we add them in below)\n            next_tag_var = forward_var + self.transitions[next_tag]\n            best_tag_id = argmax(next_tag_var)\n            bptrs_t.append(best_tag_id)\n            viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n        # Now add in the emission scores, and assign forward_var to the set\n        # of viterbi variables we just computed\n        forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1).to(device)\n        backpointers.append(bptrs_t)\n\n    # Transition to STOP_TAG\n    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n    best_tag_id = argmax(terminal_var)\n    path_score = terminal_var[0][best_tag_id]\n\n    # Follow the back pointers to decode the best path.\n    best_path = [best_tag_id]\n    for bptrs_t in reversed(backpointers):\n        best_tag_id = bptrs_t[best_tag_id]\n        best_path.append(best_tag_id)\n    # Pop off the start tag (we dont want to return that to the caller)\n    start = best_path.pop()\n    assert start == self.tag_to_ix[START_TAG]  # Sanity check\n    best_path.reverse()\n    return path_score, best_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\ndef neg_log_likelihood(self, sentence, tags):\n    \"\"\"Calculate the negative log likelihood given a sequence and labels.\n    This is used in training (only) because we don't need to create\n    and check the B-I-O tags themselves - only the score is important\n    here for calculating the loss.\"\"\"\n    feats = self._get_lstm_features(sentence)\n    forward_score = self._forward_alg(feats)\n    gold_score = self._score_sentence(feats, tags)\n    return forward_score - gold_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%add_to BiLSTM_CRF\n\ndef forward(self, sentence):\n    \"\"\"The forward pass function for training the network.\n    This is used in inference only.\"\"\"\n    # Get the emission scores (output layer) from the \n    # BiLSTM \n    lstm_feats = self._get_lstm_features(sentence)\n\n    # Find the best path, given the features.\n    score, tag_seq = self._viterbi_decode(lstm_feats)\n    return score, tag_seq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a lookup dict for all possible words and record their index\nword_to_ix = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\ntag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\nix_to_tag = {0: \"B\", 1: \"I\", 2: \"O\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\nmodel = model.to(device)\noptimizer = optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDs.head(10)\ntrainDs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Word Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainAddress = trainDs['raw_address']\nwords = nltk.tokenize.word_tokenize(trainAddress.str.cat(sep=' '))\nword_dist = nltk.FreqDist(words)\nrslt = pd.DataFrame(word_dist.most_common(100),\n                    columns=['Word', 'Frequency'])\nrslt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rslt.head(40).plot.bar(x=\"Word\", y=\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training POI"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPOI = trainDs[\"POI/street\"].str.split(\"/\").str[0].replace('', np.nan).dropna()\ntop20POI = trainPOI.value_counts()[:20]\ntop20POI\ntop20POI.plot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training Street"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainStreetName = trainDs[\"POI/street\"].str.split(\"/\").str[1].replace('', np.nan).dropna()\ntop20StreetName = trainStreetName.value_counts()[:20]\ntop20StreetName\ntop20StreetName.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}